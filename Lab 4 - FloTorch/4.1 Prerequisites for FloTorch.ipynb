{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70e22f73",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "Up to this point, previous labs have guided you through the process of building knowledge bases, constructing RAG pipelines with various configurations, posing questions, and generating answers. However, a crucial question remains: how do we determine the optimal pipeline configuration? How do we objectively evaluate their performance? This is the focus of the Lab 4 notebooks, which will walk you through the evaluation process.\n",
    "\n",
    "This notebook sets up the prerequisites for evaluating Retrieval-Augmented Generation (RAG) pipelines using FloTorch. It involves installing the FloTorch core library, loading necessary variables from a previous lab, uploading the ground truth dataset to Amazon S3, and creating a results directory for storing output files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2cd89",
   "metadata": {},
   "source": [
    "# Introduction to FloTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5f17bb",
   "metadata": {},
   "source": [
    "#### What is FloTorch?\n",
    "\n",
    "FloTorch is an open-source tool designed to streamline the optimization of Generative AI workloads on AWS. With just a few clicks, it enables rapid evaluation of Retrieval-Augmented Generation (RAG) pipelines, focusing on key metrics like accuracy, cost, and latency.\n",
    "\n",
    "#### FloTorch Demo\n",
    "[![FloTorch Demo](https://img.youtube.com/vi/00000000000/0.jpg)](https://flotorch-public.s3.us-east-1.amazonaws.com/media/FloTorch-Demo.mp4)\n",
    "\n",
    "#### Getting Started with FloTorch\n",
    "\n",
    "There are two primary ways to experience FloTorch:\n",
    "\n",
    "1.  **AWS Marketplace or Git Repository (Full Application):** For a comprehensive experience with a user-friendly interface, you can install FloTorch either through the AWS Marketplace: [https://aws.amazon.com/marketplace/pp/prodview-z5zcvloh7l3ky] or by cloning the git repository: [https://github.com/FissionAI/FloTorch](https://github.com/FissionAI/FloTorch). This method sets up the complete FloTorch stack within your AWS account, providing an intuitive UI for fine-tuning RAG hyperparameters and running experiments at scale.\n",
    "\n",
    "2.  **Python Package (Programmatic Access):** If you prefer a programmatic approach, we offer the `flotorch-core` Python package. This package includes a range of functionalities:\n",
    "    1.  Utilities for reading PDF files.\n",
    "    2.  Tools for chunking, embedding, and indexing data into VectorStorage.\n",
    "    3.  Functions for performing inference using Amazon Bedrock and SageMaker.\n",
    "    4.  Capabilities for evaluation leveraging the RAGAS framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155ed233",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f0126",
   "metadata": {},
   "source": [
    "* **Install `flotorch-core`:** Ensure the FloTorch core Python package is installed in your environment.\n",
    "* **Ground Truth Data:** The JSON file containing questions and their corresponding ground truth answers. This data is crucial for evaluating the accuracy of your RAG pipelines. Located in the `data/ground_truth_data` folder.\n",
    "* **Prompt File:** The `prompt.json` file, which defines the prompts used for querying your knowledge bases. Located in the `data/prompt.json` folder.\n",
    "* **Results Folder:** Create a `results` folder in your working directory to store the output files generated during the evaluation process.\n",
    "\n",
    "**Important Note:** This lab (Lab 4) builds upon the Knowledge Bases created in Lab 1. Specifically, it expects that you have run the following notebooks from Lab 1:\n",
    "\n",
    "* `1.1 Prerequisites.ipynb`\n",
    "* `1.2 Knowledge Base with Fixed Chunking.ipynb`\n",
    "* `1.3 Knowledge base with Semantic Chunking.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f876d2c",
   "metadata": {},
   "source": [
    "# Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ec78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42cf869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install FloTorch Core Package\n",
    "print(\"Installing flotorch-core...\")\n",
    "!pip install FloTorch-core\n",
    "print(\"flotorch-core installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf4a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Variables from Previous Lab\n",
    "import json\n",
    "with open(\"../Lab 1/variables.json\", \"r\") as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "# Display Loaded Variables\n",
    "print(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efab249",
   "metadata": {},
   "source": [
    "#### Upload Ground Truth Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4036f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "# Initialize S3 Client\n",
    "s3 = boto3.client(\"s3\", region_name=variables[\"regionName\"])\n",
    "\n",
    "# Define Function to Upload Directory to S3\n",
    "def upload_directory(path, bucket_name, data_s3_prefix):\n",
    "    \"\"\"Uploads all files from a local directory to a specified S3 bucket and prefix.\"\"\"\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            local_path = os.path.join(root, file)\n",
    "            relative_path = os.path.relpath(local_path, path)\n",
    "            s3_key = f\"{data_s3_prefix}/{relative_path}\"  # Construct the full S3 object key\n",
    "            try:\n",
    "                s3.upload_file(local_path, bucket_name, s3_key)\n",
    "                print(f\"Uploaded {local_path} to s3://{bucket_name}/{s3_key}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error uploading {local_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d5464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Paths and Upload Ground Truth Data\n",
    "ground_truth_data_path = \"./data/ground_truth_data\"\n",
    "s3_key_prefix = \"ground_truth_data\"\n",
    "s3_bucket_name = variables[\"s3Bucket\"]\n",
    "\n",
    "# Upload the entire ground_truth_data directory\n",
    "upload_directory(ground_truth_data_path, s3_bucket_name, s3_key_prefix)\n",
    "\n",
    "# Construct the S3 path to the ground truth file\n",
    "ground_truth_path = f\"s3://{s3_bucket_name}/{s3_key_prefix}/ground_truth.json\"\n",
    "\n",
    "# Store the S3 path in the variables dictionary\n",
    "variables[\"s3_ground_truth_path\"] = ground_truth_path\n",
    "\n",
    "# Print the S3 path to confirm\n",
    "print(f\"Ground truth data uploaded to: {ground_truth_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb51a8c1",
   "metadata": {},
   "source": [
    "#### Create Results Folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7806cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Results Directory\n",
    "import os\n",
    "\n",
    "# Define the path to the results folder\n",
    "results_dir = \"./results\"\n",
    "\n",
    "# Check if the directory exists, and create it if it doesn't\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    print(f\"Created directory: {results_dir}\")\n",
    "else:\n",
    "    print(f\"Directory already exists: {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a5604",
   "metadata": {},
   "source": [
    "### Export Variables for the Next Lab\n",
    "\n",
    "> **Note**: We are saving all the important configuration variables to a JSON file. This allows easy access to these variables in subsequent notebooks, ensuring consistency and avoiding the need to recreate resources in each lab of the workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6fbd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Variables to JSON File\n",
    "import json\n",
    "\n",
    "# Define the output file name\n",
    "output_file = \"variables.json\"\n",
    "\n",
    "# Write the variables dictionary to a JSON file with indentation for readability\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(variables, f, indent=4)\n",
    "\n",
    "# Print a confirmation message\n",
    "print(f\"Variables saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
